{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.A More Difficult Classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the necessary def from the mp1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_a_drawing(figsize, U, V, noise=0.0):\n",
    "    fig = plt.figure(figsize=(figsize,figsize))\n",
    "    ax = plt.subplot(111)\n",
    "    plt.axis('Off')\n",
    "    ax.set_xlim(0,figsize)\n",
    "    ax.set_ylim(0,figsize)\n",
    "    ax.fill(U, V, \"k\")\n",
    "    fig.canvas.draw()\n",
    "    imdata = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)[::3].astype(np.float32)\n",
    "    imdata = imdata + noise * np.random.random(imdata.size)\n",
    "    plt.close(fig)\n",
    "    return imdata\n",
    "\n",
    "def generate_a_rectangle(noise=0.0, free_location=False):\n",
    "    figsize = 1.0    \n",
    "    U = np.zeros(4)\n",
    "    V = np.zeros(4)\n",
    "    if free_location:\n",
    "        corners = np.random.random(4)\n",
    "        top = max(corners[0], corners[1])\n",
    "        bottom = min(corners[0], corners[1])\n",
    "        left = min(corners[2], corners[3])\n",
    "        right = max(corners[2], corners[3])\n",
    "    else:\n",
    "        side = (0.3 + 0.7 * np.random.random()) * figsize\n",
    "        top = figsize/2 + side/2\n",
    "        bottom = figsize/2 - side/2\n",
    "        left = bottom\n",
    "        right = top\n",
    "    U[0] = U[1] = top\n",
    "    U[2] = U[3] = bottom\n",
    "    V[0] = V[3] = left\n",
    "    V[1] = V[2] = right\n",
    "    return generate_a_drawing(figsize, U, V, noise)\n",
    "\n",
    "def generate_a_disk(noise=0.0, free_location=False):\n",
    "    figsize = 1.0\n",
    "    if free_location:\n",
    "        center = np.random.random(2)\n",
    "    else:\n",
    "        center = (figsize/2, figsize/2)\n",
    "    radius = (0.3 + 0.7 * np.random.random()) * figsize/2\n",
    "    N = 50\n",
    "    U = np.zeros(N)\n",
    "    V = np.zeros(N)\n",
    "    i = 0\n",
    "    for t in np.linspace(0, 2*np.pi, N):\n",
    "        U[i] = center[0] + np.cos(t) * radius\n",
    "        V[i] = center[1] + np.sin(t) * radius\n",
    "        i = i + 1\n",
    "    return generate_a_drawing(figsize, U, V, noise)\n",
    "\n",
    "def generate_a_triangle(noise=0.0, free_location=False):\n",
    "    figsize = 1.0\n",
    "    if free_location:\n",
    "        U = np.random.random(3)\n",
    "        V = np.random.random(3)\n",
    "    else:\n",
    "        size = (0.3 + 0.7 * np.random.random())*figsize/2\n",
    "        middle = figsize/2\n",
    "        U = (middle, middle+size, middle-size)\n",
    "        V = (middle+size, middle-size, middle-size)\n",
    "    imdata = generate_a_drawing(figsize, U, V, noise)\n",
    "    return [imdata, [U[0], V[0], U[1], V[1], U[2], V[2]]]\n",
    "\n",
    "def generate_dataset_classification(nb_samples, noise=0.0, free_location=False):\n",
    "    # Getting im_size:\n",
    "    im_size = generate_a_rectangle().shape[0]\n",
    "    X = np.zeros([nb_samples,im_size])\n",
    "    Y = np.zeros(nb_samples)\n",
    "    print('Creating data:')\n",
    "    for i in range(nb_samples):\n",
    "        if i % 10 == 0:\n",
    "            print(i, end=' ')\n",
    "        category = np.random.randint(3)\n",
    "        if category == 0:\n",
    "            X[i] = generate_a_rectangle(noise, free_location)\n",
    "        elif category == 1: \n",
    "            X[i] = generate_a_disk(noise, free_location)\n",
    "        else:\n",
    "            [X[i], V] = generate_a_triangle(noise, free_location)\n",
    "        Y[i] = category\n",
    "    X = (X + noise) / (255 + 2 * noise)\n",
    "    return [X, Y]\n",
    "\n",
    "def generate_test_set_classification():\n",
    "    np.random.seed(42)\n",
    "    [X_test, Y_test] = generate_dataset_classification(300, 20, True)\n",
    "    return [X_test, Y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate new training and testing set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data:\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 Creating data:\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 "
     ]
    }
   ],
   "source": [
    "[X_train, Y_train] = generate_dataset_classification(300, 20, True)\n",
    "[X_test, Y_test] = generate_test_set_classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(len(X_train), 72, 72, 1)\n",
    "X_test = X_test.reshape(len(X_test), 72, 72, 1)\n",
    "y_train = to_categorical(Y_train)\n",
    "y_test = to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(kernel_size=(5, 5), padding=\"same\",input_shape=(72, 72, 1),filters=16, activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (5, 5), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), padding=\"same\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 300 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "300/300 [==============================] - 21s 69ms/step - loss: 1.1053 - acc: 0.3733 - val_loss: 1.0795 - val_acc: 0.3300\n",
      "Epoch 2/10\n",
      "300/300 [==============================] - 21s 71ms/step - loss: 0.9745 - acc: 0.5667 - val_loss: 0.8937 - val_acc: 0.5933\n",
      "Epoch 3/10\n",
      "300/300 [==============================] - 21s 71ms/step - loss: 0.7259 - acc: 0.7000 - val_loss: 0.7476 - val_acc: 0.6733\n",
      "Epoch 4/10\n",
      "300/300 [==============================] - 21s 69ms/step - loss: 0.5612 - acc: 0.7267 - val_loss: 0.7628 - val_acc: 0.6733\n",
      "Epoch 5/10\n",
      "300/300 [==============================] - 21s 70ms/step - loss: 0.4124 - acc: 0.8467 - val_loss: 0.7061 - val_acc: 0.7033\n",
      "Epoch 6/10\n",
      "300/300 [==============================] - 21s 72ms/step - loss: 0.2652 - acc: 0.9033 - val_loss: 0.8573 - val_acc: 0.6700\n",
      "Epoch 7/10\n",
      "300/300 [==============================] - 21s 69ms/step - loss: 0.1954 - acc: 0.9300 - val_loss: 0.8468 - val_acc: 0.7200\n",
      "Epoch 8/10\n",
      "300/300 [==============================] - 21s 69ms/step - loss: 0.1151 - acc: 0.9567 - val_loss: 0.8708 - val_acc: 0.7467\n",
      "Epoch 9/10\n",
      "300/300 [==============================] - 23s 75ms/step - loss: 0.0654 - acc: 0.9900 - val_loss: 0.7941 - val_acc: 0.7667\n",
      "Epoch 10/10\n",
      "300/300 [==============================] - 22s 72ms/step - loss: 0.0405 - acc: 0.9967 - val_loss: 0.7711 - val_acc: 0.7933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb473c7c50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that finally in the training set we will get the value of loss function of 0.0405 and the accuracy rate of 0.9967."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valuate my classifier on this test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 4s 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7711150662104289, 0.7933333325386047]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The value of loss function in testing set is 0.771 and accuracy rate is 0.79."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
